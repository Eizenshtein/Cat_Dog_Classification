{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat || Dog CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAAnWVLqmXiC"
      },
      "source": [
        "Kullanılan veri seti, Kaggle Dogs & Cats yarışmasından alınan veri setinin rastgele bir alt kümesidir.\n",
        "* <a href=\"https://www.kaggle.com/c/dogs-vs-cats/overview\">Veriler</a>\n",
        "* Eğitim arşivi, köpek ve kedilerin 25.000 görüntüsünü içerir.\n",
        "* Eğitim için 2000 Görsel (1000 Kedi / 1000 Köpek)\n",
        "* Doğrulama için 400 Görsel (200 Kedi / 200 Köpek)\n",
        "* Test için 100 Görsel (50 Kedi / 50 Köpek)      Kullanılmıştır.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6yLarHmsi9t"
      },
      "source": [
        "# Connect G-Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_CPuy3r5p6",
        "outputId": "ef336aab-2277-46ca-e700-3eac8fe4d6c1"
      },
      "source": [
        "#Colab üzerinde çalışmak için Drive Bağlantısı\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tWttDC8r6VW"
      },
      "source": [
        "import os \n",
        "os.chdir(\"/gdrive/MyDrive/Dog_Cat\") "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXapWeQvso41"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq3cCxuMmDmd"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\",category=FutureWarning)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cgg6ACjtUns"
      },
      "source": [
        "**Check GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiX30I7ds4GX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4db62e-4c15-4451-bad3-a4edeec8f6cb"
      },
      "source": [
        "device = tf.config.list_physical_devices()\n",
        "if(device[0][1] == \"CPU\"):\n",
        "  print(\"GPU is Not Avaible\")\n",
        "else:\n",
        "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is Not Avaible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLLJlSYxtxjP"
      },
      "source": [
        "# Data Prepation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ96Aqn3BAPw"
      },
      "source": [
        "train_path = '/gdrive/MyDrive/Dog_Cat/train'\n",
        "valid_path = '/gdrive/MyDrive/Dog_Cat/valid'\n",
        "test_path = '/gdrive/MyDrive/Dog_Cat/test'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akIvgKE1Cu8Q"
      },
      "source": [
        "* ImageDataGenerator Belirtilen görüntüleri tensör görüntü verisi haline getirir.\n",
        "* Her veri seti için ImageDataGenerator'a preprocessing_function=tf.keras.applications.vgg16.preprocess_input belirtiyoruz burada amaç elimizdeki verileri VGG16 modeline fit etmek için uygun hale getirmek"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUWxjx7jy_Y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8adf0a2-c2aa-433b-e63d-7ca0bb458a42"
      },
      "source": [
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksA2b-7O0C9"
      },
      "source": [
        "# Build VGG16 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUBcdUv2pkff"
      },
      "source": [
        "* VGG, Oxford Üniversitesi'nden K. Simonyan ve A. Zisserman tarafından “Büyük Ölçekli Görüntü Tanıma için Çok Derin Evrişimli Ağlar” makalesinde önerilen evrişimli bir sinir ağı modelidir.\n",
        "* Model, 1000 sınıfa ait 14 milyondan fazla görüntüden oluşan bir veri seti olan ImageNet'te %92,7'lik ilk 5 test doğruluğuna ulaşıyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzUIiiiSO3-h",
        "outputId": "4f0b2c72-62c4-4f0c-e3bd-a95772060727"
      },
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "553476096/553467096 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZOY-JekPGNn",
        "outputId": "821176a9-4d9d-412d-89c7-fcd0e5ddb6db"
      },
      "source": [
        "vgg16_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BEZoLkDPIkn"
      },
      "source": [
        "#Model varsayılan olarak indirildiğinde son katman 1000 sınıf için ayarlanmıştır bunu bu model için 2 ye düşürülmesi gerekiyor\n",
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "    model.add(layer)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_a9OfmlSA_M"
      },
      "source": [
        "#Katmanların ağırlıklarını VGG16 dan aldığı için tekrar eğitilmemesi için  katmanları eğitime kapatıyoruz\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nv5xC4iSGKY"
      },
      "source": [
        "#En sonra 2 birimli bir çıkış katmanı ekliyoruz\n",
        "model.add(Dense(units = 2 ,activation=\"softmax\"))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WzACJMISVaP",
        "outputId": "f0dcf2cd-6d58-4f24-98ef-dfb6c2c8a880"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLU91TvBS00A"
      },
      "source": [
        "# Train VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRY5UmZkm6NI"
      },
      "source": [
        "#Modeli kaydetmek için gerekli basit fonksiyon\n",
        "def save_model(model):\n",
        "  model.save('dog_cat.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvfoS_i_SW_w"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bxlCgeUTvww",
        "outputId": "bb4a3f9f-f80d-42e1-cda0-80ee1a2e63ae"
      },
      "source": [
        "#Modelin Eğitilmesi\n",
        "model.fit(x=train_batches,validation_data=valid_batches,epochs=10,verbose=2)\n",
        "save_model(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "200/200 - 348s - loss: 0.2212 - accuracy: 0.9085 - val_loss: 0.1133 - val_accuracy: 0.9500\n",
            "Epoch 2/10\n",
            "200/200 - 31s - loss: 0.0684 - accuracy: 0.9790 - val_loss: 0.0815 - val_accuracy: 0.9650\n",
            "Epoch 3/10\n",
            "200/200 - 31s - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.0718 - val_accuracy: 0.9700\n",
            "Epoch 4/10\n",
            "200/200 - 31s - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.0672 - val_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "200/200 - 31s - loss: 0.0267 - accuracy: 0.9930 - val_loss: 0.0664 - val_accuracy: 0.9750\n",
            "Epoch 6/10\n",
            "200/200 - 31s - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.0735 - val_accuracy: 0.9675\n",
            "Epoch 7/10\n",
            "200/200 - 31s - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.0707 - val_accuracy: 0.9775\n",
            "Epoch 8/10\n",
            "200/200 - 31s - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0693 - val_accuracy: 0.9750\n",
            "Epoch 9/10\n",
            "200/200 - 31s - loss: 0.0108 - accuracy: 0.9995 - val_loss: 0.0719 - val_accuracy: 0.9775\n",
            "Epoch 10/10\n",
            "200/200 - 31s - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.0732 - val_accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL3HAtVyuqC_"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"dog_cat.h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiObuCUPmuHg"
      },
      "source": [
        "#Test verilerinin tahmin edilmesi\n",
        "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aACs3n15tvBu"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        " \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "oWwrmXyamvof",
        "outputId": "5e50a351-131d-45ce-e0dd-a6b58a52caa7"
      },
      "source": [
        "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
        "cm_plot_labels = ['cat','dog']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[50  0]\n",
            " [ 1 49]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}